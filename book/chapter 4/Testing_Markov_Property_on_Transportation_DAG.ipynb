{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# Chapter 4 - Testing the Causal Markov Property on the Transportation DAG\n",
    "\n",
    "The notebook is a code companion to chapter 4 of the book [Causal Machine Learning](https://www.manning.com/books/causal-machine-learning) by Robert Osazuwa Ness. This is not an exact copy of the code in Chapter 4, but it captures the core elements.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/altdeep/causalML/blob/master/book/chapter%204/Testing_Markov_Property_on_Transportation_DAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xQs8VigU0TdV"
   },
   "outputs": [],
   "source": [
    "#!pip install pgmpy==0.1.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal relationships impose conditional independence constraints on the joint probability distribution of the variables in the data generating process. [D-separation](https://networkx.org/documentation/stable/reference/algorithms/d_separation.html) is a graphical criterion used to determine whether a set of variables is independent of another set of variables, given a third set. The causal Markov assumption says that if our selected causal DAG is true, then variables that are d-separated in the graph will be conditionally independent. Let’s revisit the transportation model:\n",
    "\n",
    "![transportation DAG](images/transportation_DAG.png)\n",
    "\n",
    "* Age (A): Recorded as young (young) for individuals up to and including 29 years, adult (adult) for individuals between 30 and 60 years old (inclusive), and old (old) for people 61 and over.\n",
    "* Gender (S): The self-reported gender of an individual, recorded as male (M), female (F), or other (O).\n",
    "* Education (E): The highest level of education or training completed by the individual, recorded either high school (high) or university degree (uni).\n",
    "* Occupation (O): Employee (emp) or a self-employed (self) worker.\n",
    "* Residence (R): The population size of the city the individual lives in, recorded as small (small) or big (big).\n",
    "* Travel (T): The means of transport favored by the individual, recorded as car (car), train (train) or other (other)\n",
    "\n",
    "Age (A) and Gender (S) determine Education (E). Education causes Occupation (O) and Residence (R). Occupation and Residence causes Transportation (T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lKE0cLBEyQpc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.base.DAG import DAG\n",
    "from pgmpy.estimators.CITests import chi_square\n",
    "from pgmpy.independencies import IndependenceAssertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build the graph. The method `get_independencies` will enumerate the d-separation statements that hold for this graph. Note that pgmpy attempts to remove redundant d-separations from this enumeration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "me9JRP0hyK3o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A ⟂ S)\n",
      "(A ⟂ O, R, T | E)\n",
      "(A ⟂ O, R, T | E, S)\n",
      "(A ⟂ T | O, R)\n",
      "(A ⟂ R, T | O, E)\n",
      "(A ⟂ O, T | R, E)\n",
      "(A ⟂ O, R | E, T)\n",
      "(A ⟂ T | O, R, S)\n",
      "(A ⟂ R, T | O, E, S)\n",
      "(A ⟂ O, T | R, E, S)\n",
      "(A ⟂ O, R | T, E, S)\n",
      "(A ⟂ T | O, R, E)\n",
      "(A ⟂ R | O, E, T)\n",
      "(A ⟂ O | R, E, T)\n",
      "(A ⟂ T | O, R, E, S)\n",
      "(A ⟂ R | T, O, E, S)\n",
      "(A ⟂ O | T, R, E, S)\n",
      "(S ⟂ A)\n",
      "(S ⟂ O, R, T | E)\n",
      "(S ⟂ O, R, T | A, E)\n",
      "(S ⟂ T | O, R)\n",
      "(S ⟂ R, T | O, E)\n",
      "(S ⟂ O, T | R, E)\n",
      "(S ⟂ O, R | E, T)\n",
      "(S ⟂ T | A, O, R)\n",
      "(S ⟂ R, T | A, O, E)\n",
      "(S ⟂ O, T | A, R, E)\n",
      "(S ⟂ O, R | A, E, T)\n",
      "(S ⟂ T | O, R, E)\n",
      "(S ⟂ R | O, E, T)\n",
      "(S ⟂ O | R, E, T)\n",
      "(S ⟂ T | A, O, E, R)\n",
      "(S ⟂ R | A, O, E, T)\n",
      "(S ⟂ O | A, R, E, T)\n",
      "(O ⟂ A, R, S | E)\n",
      "(O ⟂ R, S | A, E)\n",
      "(O ⟂ A, R | E, S)\n",
      "(O ⟂ A, S | R, E)\n",
      "(O ⟂ A, S | E, T)\n",
      "(O ⟂ R | A, E, S)\n",
      "(O ⟂ S | A, R, E)\n",
      "(O ⟂ S | A, E, T)\n",
      "(O ⟂ A | R, E, S)\n",
      "(O ⟂ A | T, E, S)\n",
      "(O ⟂ A, S | R, E, T)\n",
      "(O ⟂ S | A, R, E, T)\n",
      "(O ⟂ A | T, R, E, S)\n",
      "(R ⟂ A, O, S | E)\n",
      "(R ⟂ O, S | A, E)\n",
      "(R ⟂ A, O | E, S)\n",
      "(R ⟂ A, S | O, E)\n",
      "(R ⟂ A, S | E, T)\n",
      "(R ⟂ O | A, E, S)\n",
      "(R ⟂ S | A, O, E)\n",
      "(R ⟂ S | A, E, T)\n",
      "(R ⟂ A | O, E, S)\n",
      "(R ⟂ A | T, E, S)\n",
      "(R ⟂ A, S | O, E, T)\n",
      "(R ⟂ S | A, O, E, T)\n",
      "(R ⟂ A | T, O, E, S)\n",
      "(E ⟂ T | O, R)\n",
      "(E ⟂ T | A, O, R)\n",
      "(E ⟂ T | O, R, S)\n",
      "(E ⟂ T | A, O, S, R)\n",
      "(T ⟂ A, S | E)\n",
      "(T ⟂ S | A, E)\n",
      "(T ⟂ A, E, S | O, R)\n",
      "(T ⟂ A, S | O, E)\n",
      "(T ⟂ A, S | R, E)\n",
      "(T ⟂ A | E, S)\n",
      "(T ⟂ E, S | A, O, R)\n",
      "(T ⟂ S | A, O, E)\n",
      "(T ⟂ S | A, R, E)\n",
      "(T ⟂ A, S | O, R, E)\n",
      "(T ⟂ A, E | O, R, S)\n",
      "(T ⟂ A | O, E, S)\n",
      "(T ⟂ A | R, E, S)\n",
      "(T ⟂ S | A, O, E, R)\n",
      "(T ⟂ E | A, O, S, R)\n",
      "(T ⟂ A | O, R, E, S)\n",
      "Total number of assertions: 80\n"
     ]
    }
   ],
   "source": [
    "G = DAG()\n",
    "G.add_edges_from(\n",
    "    [\n",
    "      ('A','E'),\n",
    "      ('S','E'),\n",
    "      ('E','O'),\n",
    "      ('E','R'),\n",
    "      ('O','T'),\n",
    "      ('R','T')\n",
    "    ]\n",
    ")\n",
    "\n",
    "dseps = G.get_independencies()\n",
    "print(dseps)\n",
    "print(f\"Total number of assertions: {len(dseps.get_assertions())}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our DAG by actually testing these if there is evidence of this conditional independence in the data. First, let's load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_url = \"https://raw.githubusercontent.com/altdeep/causalML/master/datasets/transportation_survey.csv\"\n",
    "full_data = pd.read_csv(survey_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way (but not the only way) to test for conditional independence is to run a classical [frequentist statistical hypothesis test](https://en.wikipedia.org/wiki/Statistical_hypothesis_test) for independence. Below, I write a function that will run a [Chi-square test for independence](https://en.wikipedia.org/wiki/Chi-squared_test). The core element of the code is the function:\n",
    "\n",
    "`chi_square(X=X, Y=Y, Z=Z, data=data, boolean=True, significance_level=significance)`\n",
    "\n",
    "If the `boolean` argument is False, the test returns a tuple containing chi-squared test statistic, the p_value, and the [degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)) used to calculate the test statistic and p-value. In this test, lower p-values are evidence against independence. So lower p-values are evidence against our model.\n",
    "\n",
    "For each of the above d-separation statements, I run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(A ⟂ S): (1.9853449962420004, 0.37058497877829005, 2), (A ⟂ O | E): (2.0985435790243034, 0.7176399600516277, 4), (A ⟂ R | E): (2.8026991954963454, 0.5913668739613169, 4), (A ⟂ T | E): (10.693950409937166, 0.21965055000059597, 8), (A ⟂ O | E, S): (6.5410721048388965, 0.5868555930315218, 8), (A ⟂ R | E, S): (9.27447234495111, 0.31967361894631896, 8), (A ⟂ T | E, S): (16.9969080647128, 0.3857972070728527, 16), (A ⟂ T | O, R): (17.303945408152316, 0.13851716499180977, 12), (A ⟂ R | O, E): (3.8133663932876196, 0.7019157718399125, 6), (A ⟂ T | O, E): (14.661327352311131, 0.26048193401591613, 12), (A ⟂ O | R, E): (3.1768654060661357, 0.7863434276852411, 6), (A ⟂ T | R, E): (13.067469907330542, 0.4426137158614294, 13), (A ⟂ O | E, T): (4.857705338926742, 0.9004783671841152, 10), (A ⟂ R | E, T): (7.405368145500495, 0.6867011056470256, 10), (A ⟂ T | O, R, S): (25.44919823281326, 0.276079664102723, 22), (A ⟂ R | O, E, S): (9.337520274798791, 0.40671936433378186, 9), (A ⟂ T | O, E, S): (16.260859790904792, 0.6398084364487099, 19), (A ⟂ O | R, E, S): (7.990643879663905, 0.629750872060554, 10), (A ⟂ T | R, E, S): (24.15228381986027, 0.5672577559865835, 26), (A ⟂ O | S, E, T): (13.43877591367871, 0.764875660171693, 18), (A ⟂ R | S, E, T): (18.25402572529846, 0.5706785464276498, 20), (A ⟂ T | O, R, E): (17.4152031984384, 0.42659682069890104, 17), (A ⟂ R | O, E, T): (8.217568484451899, 0.6936919627876027, 11), (A ⟂ O | R, E, T): (7.382613840194036, 0.8313283656285512, 12), (A ⟂ T | O, R, E, S): (23.52626269483968, 0.7519279693571035, 29), (A ⟂ R | O, S, E, T): (18.44246404604757, 0.6208576926923874, 21), (A ⟂ O | S, R, E, T): (17.9402712465741, 0.5913429793037752, 20), (S ⟂ O | E): (0.07543282589593173, 0.9629859925311869, 2), (S ⟂ R | E): (0.7329729141743667, 0.6931655238992458, 2), (S ⟂ T | E): (2.0391835817343282, 0.7285519218572771, 4), (S ⟂ O | A, E): (0.27129451228430057, 0.9981483682438302, 5), (S ⟂ R | A, E): (4.921039466943525, 0.4255925299455995, 5), (S ⟂ T | A, E): (7.537881259167033, 0.820121437562396, 12), (S ⟂ T | O, R): (3.3103642737619983, 0.7690047001719409, 6), (S ⟂ R | O, E): (0.7869381332712988, 0.8525886408966638, 3), (S ⟂ T | O, E): (2.497521629870305, 0.9272835730957228, 7), (S ⟂ O | R, E): (0.11102138564494796, 0.9904827837617047, 3), (S ⟂ T | R, E): (2.5811225228859613, 0.920865597390092, 7), (S ⟂ O | E, T): (0.0, 1.0, 5), (S ⟂ R | E, T): (0.44139801101040754, 0.9941122851597343, 5), (S ⟂ T | A, O, R): (9.414397836994272, 0.8548728658657164, 15), (S ⟂ R | A, O, E): (4.858626145873736, 0.5620692420306916, 6), (S ⟂ T | A, O, E): (7.938345769063372, 0.9262306791644265, 15), (S ⟂ O | A, R, E): (0.3858976125853738, 0.9989633455952024, 6), (S ⟂ T | A, R, E): (13.20499726646444, 0.8684162174402956, 20), (S ⟂ O | A, E, T): (0.34089191493283577, 0.9999693036695166, 8), (S ⟂ R | A, E, T): (4.668079986279347, 0.9817919833354388, 13), (S ⟂ T | O, R, E): (3.2840884493859024, 0.9739262234894116, 10), (S ⟂ R | O, E, T): (0.6030234729934986, 0.9963498942791321, 6), (S ⟂ O | R, E, T): (0.000161930006377551, 0.9999999999999115, 6), (S ⟂ T | A, O, E, R): (13.406998988229766, 0.9426050285948762, 23), (S ⟂ R | A, O, E, T): (4.5516245051348, 0.9911270368402301, 14), (S ⟂ O | A, R, E, T): (0.8541785652641886, 0.9990124485373111, 8), (O ⟂ R | E): (0.0, 1.0, 2), (O ⟂ R | A, E): (0.0, 1.0, 5), (O ⟂ R | E, S): (0.0, 1.0, 4), (O ⟂ R | A, E, S): (0.0, 1.0, 7), (E ⟂ T | O, R): (7.015260050091365, 0.31943826436448475, 6), (E ⟂ T | A, O, R): (6.989112727531359, 0.9027117532757623, 13), (E ⟂ T | O, R, S): (7.177867902389551, 0.8456388227763408, 12), (E ⟂ T | A, O, S, R): (12.171036515419436, 0.9537455174857967, 22)}\n"
     ]
    }
   ],
   "source": [
    "def test_dsep(dsep: IndependenceAssertion, data, boolean=True, significance = .01):\n",
    "  test_outputs = []\n",
    "  for X in list(dsep.get_assertion()[0]):\n",
    "    for Y in list(dsep.get_assertion()[1]):\n",
    "      Z = list(dsep.get_assertion()[2])\n",
    "      test_result = chi_square(X=X, Y=Y, Z=Z, data=data, boolean=boolean, significance_level=significance)\n",
    "      test_outputs.append((IndependenceAssertion(X, Y, Z), test_result))\n",
    "  return test_outputs\n",
    "\n",
    "results = [test_dsep(dsep, data=full_data, boolean=False) for dsep in dseps.get_assertions()]\n",
    "results_flat = [item for sublist in results for item in sublist]\n",
    "results = {k: v for k, v in results_flat}\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make life a bit easier, we can define a cut-off and evaluate how many tests meet (or fail to meet) the cut-off. Since this is a statistical hypothesis test, the most straightforward cut-off is a [significance level](https://en.wikipedia.org/wiki/Statistical_significance), against which we can directly compare the p-value. If the `boolean` argument in `chi_square` is true and we provide a significance level, then the test will return True if the p_value of the test is greater than  the significance_level (evidence in favor of independence), otherwise it will returns False. Below, we'll look of the proportion of tests that beat this significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(A ⟂ S): True, (A ⟂ O | E): True, (A ⟂ R | E): True, (A ⟂ T | E): True, (A ⟂ O | E, S): True, (A ⟂ R | E, S): True, (A ⟂ T | E, S): True, (A ⟂ T | O, R): True, (A ⟂ R | O, E): True, (A ⟂ T | O, E): True, (A ⟂ O | R, E): True, (A ⟂ T | R, E): True, (A ⟂ O | E, T): True, (A ⟂ R | E, T): True, (A ⟂ T | O, R, S): True, (A ⟂ R | O, E, S): True, (A ⟂ T | O, E, S): True, (A ⟂ O | R, E, S): True, (A ⟂ T | R, E, S): True, (A ⟂ O | S, E, T): True, (A ⟂ R | S, E, T): True, (A ⟂ T | O, R, E): True, (A ⟂ R | O, E, T): True, (A ⟂ O | R, E, T): True, (A ⟂ T | O, R, E, S): True, (A ⟂ R | O, S, E, T): True, (A ⟂ O | S, R, E, T): True, (S ⟂ O | E): True, (S ⟂ R | E): True, (S ⟂ T | E): True, (S ⟂ O | A, E): True, (S ⟂ R | A, E): True, (S ⟂ T | A, E): True, (S ⟂ T | O, R): True, (S ⟂ R | O, E): True, (S ⟂ T | O, E): True, (S ⟂ O | R, E): True, (S ⟂ T | R, E): True, (S ⟂ O | E, T): True, (S ⟂ R | E, T): True, (S ⟂ T | A, O, R): True, (S ⟂ R | A, O, E): True, (S ⟂ T | A, O, E): True, (S ⟂ O | A, R, E): True, (S ⟂ T | A, R, E): True, (S ⟂ O | A, E, T): True, (S ⟂ R | A, E, T): True, (S ⟂ T | O, R, E): True, (S ⟂ R | O, E, T): True, (S ⟂ O | R, E, T): True, (S ⟂ T | A, O, E, R): True, (S ⟂ R | A, O, E, T): True, (S ⟂ O | A, R, E, T): True, (O ⟂ R | E): True, (O ⟂ R | A, E): True, (O ⟂ R | E, S): True, (O ⟂ R | A, E, S): True, (E ⟂ T | O, R): True, (E ⟂ T | A, O, R): True, (E ⟂ T | O, R, S): True, (E ⟂ T | A, O, S, R): True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [test_dsep(dsep, data=full_data, boolean=True, significance=.1) for dsep in dseps.get_assertions()]\n",
    "results_flat = [item for sublist in results for item in sublist]\n",
    "results = {k: v for k, v in results_flat}\n",
    "print(results)\n",
    "sum(results.values())/len(dseps.get_assertions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is not conceptually perfect, for reasons outlined in the book. For one, p-values are dependent on the size of the data. Typically, the more data you have, the more independent variables start to look dependent due to coincidental [spurious correlation](https://en.wikipedia.org/wiki/Spurious_relationship). Specifically, p-values depend on the size of the data, the bigger the data, the smaller the p-values (evidence against indepedence). For example, we see that the proportion goes down if we only use 30 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(A ⟂ S): True, (A ⟂ O | E): True, (A ⟂ R | E): True, (A ⟂ T | E): True, (A ⟂ O | E, S): True, (A ⟂ R | E, S): True, (A ⟂ T | E, S): True, (A ⟂ T | O, R): True, (A ⟂ R | O, E): True, (A ⟂ T | O, E): True, (A ⟂ O | R, E): True, (A ⟂ T | R, E): True, (A ⟂ O | E, T): True, (A ⟂ R | E, T): True, (A ⟂ T | O, R, S): True, (A ⟂ R | O, E, S): True, (A ⟂ T | O, E, S): True, (A ⟂ O | R, E, S): True, (A ⟂ T | R, E, S): True, (A ⟂ O | S, E, T): True, (A ⟂ R | S, E, T): True, (A ⟂ T | O, R, E): True, (A ⟂ R | O, E, T): True, (A ⟂ O | R, E, T): True, (A ⟂ T | O, R, E, S): True, (A ⟂ R | O, S, E, T): True, (A ⟂ O | S, R, E, T): True, (S ⟂ O | E): True, (S ⟂ R | E): True, (S ⟂ T | E): True, (S ⟂ O | A, E): True, (S ⟂ R | A, E): True, (S ⟂ T | A, E): True, (S ⟂ T | O, R): True, (S ⟂ R | O, E): True, (S ⟂ T | O, E): True, (S ⟂ O | R, E): True, (S ⟂ T | R, E): True, (S ⟂ O | E, T): True, (S ⟂ R | E, T): True, (S ⟂ T | A, O, R): True, (S ⟂ R | A, O, E): True, (S ⟂ T | A, O, E): True, (S ⟂ O | A, R, E): True, (S ⟂ T | A, R, E): True, (S ⟂ O | A, E, T): True, (S ⟂ R | A, E, T): True, (S ⟂ T | O, R, E): True, (S ⟂ R | O, E, T): True, (S ⟂ O | R, E, T): True, (S ⟂ T | A, O, E, R): True, (S ⟂ R | A, O, E, T): True, (S ⟂ O | A, R, E, T): True, (O ⟂ R | E): False, (O ⟂ R | A, E): False, (O ⟂ R | E, S): False, (O ⟂ R | A, E, S): False, (E ⟂ T | O, R): True, (E ⟂ T | A, O, R): True, (E ⟂ T | O, R, S): True, (E ⟂ T | A, O, S, R): True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 30\n",
    "data = full_data[:N]\n",
    "results = [test_dsep(dsep, data=data, boolean=True, significance=.1) for dsep in dseps.get_assertions()]\n",
    "results_flat = [item for sublist in results for item in sublist]\n",
    "results = {k: v for k, v in results_flat}\n",
    "print(results)\n",
    "sum(results.values())/len(dseps.get_assertions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3PhIBh8ye8o"
   },
   "source": [
    "## Alternatives to canonical statistical tests for independence\n",
    "\n",
    "There are alternatives to using traditional \"parametric\" (i.e., use chi-square, Normal distribution, or another canonical distribution to calculate a p-value) statistical hypothesis testing to test the causal Markov assumption. The library [PyWhy-Stats](https://github.com/py-why/pywhy-stats) has some more sophisticated approaches that can be applied towards causal inference. You can also simply try prediction; if (S ⟂ T | E), then a model that predicts S given E and T should not perform much better than an model that predicts S only given E.\n",
    "\n",
    "Don't get too hung up on statistical rigor -- the goal is just to evaluate your causal DAG. You want to quickly <i>falsify</i> your causal DAG if it is a bad model and move on to finding a good one."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
