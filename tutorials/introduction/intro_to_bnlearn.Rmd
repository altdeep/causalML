---
title: "Causal Generative Modeling with Bayesian Networks and R's bnlearn package"
output:
  html_document:
    df_print: paged
---

```{r, 02_setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path="fig/")
```

```{r}
library(bnlearn)
```

## Installing bnlearn

Open RStudio and in console type:

```
install.packages("bnlearn")
install.packages("Rgraphviz")
install.packages("png")
```

If you experience problems installing **Rgraphviz**, try the following script:

```
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("Rgraphviz")
```

Another way to install a package in R is to go to the "Packages" tab, and click on the "Install" button.

```{r, 02_install, fig.height=7, fig.width =7, echo=FALSE, fig.align='center', message=FALSE}
library(png)
library(grid)
library(Rgraphviz)
img <- readPNG("../fig/installPackage.png")
grid.raster(img)
```

Then type “bnlearn” in the window that appears and click on the install button. Do the same thing for the other package.

```{r, 02_installPackWindow, fig.height=4, fig.width =4, echo=FALSE, fig.align='center'}
img <- readPNG("../fig/installPackWindow.png")
grid.raster(img)
```

## Understanding the directed acyclic graph (DAG) representation

In this section, we introduce the survey data set and show how we can visualize it with bnlearn package.

### The _survey data_ dataset

_survey data_ is a data set that focuses on how public transport varies across social groups. It includes the following factors (discrete variables):

- **Age (A):** It is recorded as *young* (**young**) for individuals below 30 years, *adult* (**adult**) for individuals between 30 and 60 years old, and *old* (**old**) for people older than 60.

- **Sex (S):** The biological sex of individual, recorded as *male* (**M**) or *female* (**F**).

- **Education (E):** The highest level of education or training completed by the individual, recorded either *high school* (**high**) or *university degree* (**uni**).

- **Occupation (O):** It is recorded as an *employee* (**emp**) or a *self employed* (**self**) worker.

- **Residence (R):** The size of the city the individual lives in, recorded as *small* (**small**) or *big* (**big**).

- **Travel (T):** The means of transport favoured by the individual, recorded as *car* (**car**), *train* (**train**) or *other* (**other**)

Travel is the *target* of the survey, the quantity of interest whose behaviour is under investigation.

###  Buiding a causal DAG

We can represent the causal relationships between the variables in the survey data by a directed graph where each node corresponds to a variable in data and each edge represents conditional dependencies between pairs of variables.

In bnlearn, we can graphically represent the relationships between variables in survey data like this:

```{r, 02_survey_dag, fig.width=3, fig.height=3, fig.align='center', message=FALSE}
# empty graph
dag <- empty.graph(nodes = c("A","S","E","O","R","T"))
arc.set <- matrix(c("A", "E",
                    "S", "E",
                    "E", "O",
                    "E", "R",
                    "O", "T",
                    "R", "T"),
                  byrow = TRUE, ncol = 2,
                  dimnames = list(NULL, c("from", "to")))
arcs(dag) <- arc.set
nodes(dag)
arcs(dag)
```

You can either use the simple **plot** function or use the **graphviz.plot** function from **Rgraphviz** package.

```{r, 02_plot_dag}
# plot dag with plot function
plot(dag)
```


```{r, 02_layouts, fig.width=4, fig.height=4, fig.align='center'}
graphviz.plot(dag)
```

Plotting with graphviz also allows you to adjust the layout of the graph, the shape of subsets of nodes, as well as the color and thinkness of edges.

We call this a causal DAG because we have assumed that the edges we encoded represent our causal assumptions about the system.

### Learning a (causal) DAG from data

The strength of the `bnlearn` library is it's set of algorithsm for learning DAGs, including causal DAGs, from data.

However, this is a subject that warrants its own tutorial.  We won't address the topic here.  To learn more, I suggest visiting [`bnlearn`'s website](www.bnlearn.com).

## The causal DAG as a representation of joint probability

Any DAG we might specify for this data represents a factorization of the joint probability distribution of the variables in this data.  The DAG that aligns with our causal assumptions is just one of such factorizations  That said, it is the most useful factorization because the factors correspond to independent causal mechanisms we assume to be invariant across data sets.

In this section we show how to add custom probability distributions to a DAG, as well as how to estimate the parameters of the conditional probability distribution using maximum likelihood estimation or Bayesian estimation.

### Specifying the probability distributions on your own

Given the causal DAG, the joint probability distribution of the survey data variables factorizes as follows:

$Pr(A, S, E, O, R, T) = Pr(A) Pr(S) Pr(E | A, S) Pr(O | E) Pr(R | E) Pr(T | O, R).$

```{r, 02_cpt_build}
A.lv <- c("young", "adult", "old")
S.lv <- c("M", "F")
E.lv <- c("high", "uni")
O.lv <- c("emp", "self")
R.lv <- c("small", "big")
T.lv <- c("car", "train", "other")

A.prob <- array(c(0.3,0.5,0.2), dim = 3, dimnames = list(A = A.lv))
S.prob <- array(c(0.6,0.4), dim = 2, dimnames = list(S = S.lv))
E.prob <- array(c(0.75,0.25,0.72,0.28,0.88,0.12,0.64,0.36,0.70,0.30,0.90,0.10), dim = c(2,3,2), dimnames = list(E = E.lv, A = A.lv, S = S.lv))
O.prob <- array(c(0.96,0.04,0.92,0.08), dim = c(2,2), dimnames = list(O = O.lv, E = E.lv))
R.prob <- array(c(0.25,0.75,0.2,0.8), dim = c(2,2), dimnames = list(R = R.lv, E = E.lv))
T.prob <- array(c(0.48,0.42,0.10,0.56,0.36,0.08,0.58,0.24,0.18,0.70,0.21,0.09), dim = c(3,2,2), dimnames = list(T = T.lv, O = O.lv, R = R.lv))
cpt <- list(A = A.prob, S = S.prob, E = E.prob, O = O.prob, R = R.prob, T = T.prob)
```


```{r, 02_custom_cpt}
# custom cpt table
cpt
```

Now that we have defined both the causal DAG and the local distribution corresponding to each variable, we can combine them to form a fully-specified causal Bayesian network. We combine the DAG we stored in `dag` and a list containing the local
distributions, which we will call `cpt`, into an object of class **bn.fit** called bn.

```{r, 02_custom_fit}
# fit cpt table to network
bn <- custom.fit(dag, cpt)
```

## Estimating parameters of conditional probability tables

So far, we have assumed to know both the causal DAG and the parameters of the local distributions defining the causal BN.

This is a plausible scenario if we indeed assume the DAG is causal.  In the causal case, each CPT represents an independent mechanism that we assume is fairly invariant.  So we could encode our prior knowledge about these mechanisms directly in the form of parameter values.

However, in the context of machine learning, most of the time we are going to learn these parameter values from data.

Let's read the survey data:

```{r, 02_head_survey}
survey <- read.table("../data/survey.txt", header = TRUE)
survey[] <- lapply(survey, function(x) as.factor(x)) #convert column types from character to factors
head(survey)
```

In the case of this survey, and of discrete causal BNs in general, the parameters to estimate are the conditional probabilities in the local distributions. They can be estimated, for example, by the corresponding empirical frequencies in the data set, e.g.,

$\hat{Pr}(O = emp | E = high) = \frac{\hat{Pr}(O = emp, E = high)}{\hat{Pr}(E = high)}= \frac{\text{number of observations for which O = emp and E = high}}{\text{number of observations for which E = high}}$

This yields the classic frequentist and maximum likelihood estimates. In bnlearn, we can compute them with the **bn.fit** function. **bn.fit** complements the **custom.fit** function we used in the previous section; the latter constructs a BN using a set of custom parameters specified by the user, while the former estimates the same from the data.

```{r, 02_bn_mle}
bn.mle <- bn.fit(dag, data = survey, method = "mle")
bn.mle
```

Note that we assume we know the structure of the DAG, so `dag` is an input of **bn.fit** function.

As an alternative, we can also do Bayesian estimation of the parameters.  This will provide the maximum a posterior point values of the posterior. The Bayesian modeling depends on the data type, in the discrete case, it makes use of the Dirichlet conjugate prior.

To use Bayesian estimation, set the `method` argument of `bn.fit` must be set to `"bayes"`.

```{r, 02_bn_bayes}
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 10)
```

The estimated posterior probabilities are computed from an uniformed prior over each conditional probability table. `iss` is an optional argument, whose name stands for imaginary sample size (also known as equivalent sample size).  It determines how much weight is assigned to the prior distribution compared to the data when computing the posterior. The weight is specified as the size of an imaginary sample supporting the prior distribution.

## Predicting the value of a latent variable

After we've train the model, there will often be cases where we need to apply it to data with unobserved (latent) variables.

The code below demonstrates fitting a model on the first 2000 points of a sample data set, and then predicting the value of the variable "A" on the remaining values of the data set.

```{r, 02_head_predicted}
# predicting a variable in the test set.
model <- bn.fit(
    model2network("[A][B][E][G][C|A:B][D|B][F|A:D:E:G]"),
    gaussian.test[1:2000, ]
)
test <- gaussian.test[2001:nrow(gaussian.test),]
predicted <- predict(
    model,
    node = "A",
    data = test,
    method = "bayes-lw")

plot(test$A, predicted, xlab = "actual", ylab = "predicted")
```

`bayes-lw` is the inference method used to infer the latent value.  Specifically, `bnlearn` uses a fairly light-weight inference technique called likelihood weighting.

Note that `bnlearn` can be combined with R libraries that provide better inference algorithms for graphical models, such as [gRain](https://cran.r-project.org/web/packages/gRain/vignettes/gRain-intro.pdf).  However, for more powerful infernce, you might consider reimplementing your model in a probabilistic programming language such as Stan.

## Contact me

If you have any questions about the bnlearn tutorial please email me at ```mohammadtaheri.s@northeastern.edu``` (Sara Taheri) . I will be happy to schedule a zoom call with you to answer your questions. 
