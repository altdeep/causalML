{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concentric Circles - \"Donuts\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pyro import poutine\n",
    "import torch\n",
    "import pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donuts Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generator for the Donuts Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From sklearn's [make_circles](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html) function, we create a dataset with chosen noise and factor variables:\n",
    "* noise - Standard deviation of Gaussian noise added to the data as a double value\n",
    "* factor - Scale factor between inner and outer circle as a double value ranging from 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DonutsDataset's make_dataset returns a dataset containing:\n",
    "* x1 - array of the generated samples of x1 from the pairs of X\n",
    "* x2 - array of the generated samples of x2 from the pairs of X\n",
    "* label - array of the the integer labels (0 or 1) for class membership of each X sample\n",
    "* noise - the noise value defined in data creation\n",
    "* factor - the factor value defined in data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data generating process that is modeled in the counterfactual_donuts_tutorial and that counterfactual inference is performed for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DonutsDataset(Dataset):\n",
    "    def __init__(self, n_samples, hole, noise=None, factor=None):\n",
    "        super().__init__()\n",
    "        self.data = self.make_dataset(n_samples, hole, noise, factor)\n",
    "\n",
    "    def make_dataset(self, n_samples, hole, noise=None, factor=None):\n",
    "        output = None\n",
    "        if not noise:\n",
    "            output = hole.model()\n",
    "            noise = output[0][1].item()\n",
    "        if not factor:\n",
    "            output = hole.model() if output is None else output\n",
    "            factor = output[1][1].item()\n",
    "        self.noise_scalar = noise\n",
    "        self.factor_scalar = factor\n",
    "        X, y = datasets.make_circles(n_samples=n_samples, noise=noise, factor=factor)\n",
    "        dataset = {'noise': (torch.ones([n_samples]).view(-1, 1)*noise).float(), \n",
    "                   'factor': (torch.ones([n_samples]).view(-1, 1)*factor).float(),\n",
    "                   'label': torch.tensor(y).view(-1, 1).float(),\n",
    "                   'x1': torch.tensor(X[:, 0]).view(-1, 1).float(),\n",
    "                   'x2': torch.tensor(X[:, 1]).view(-1, 1).float()}\n",
    "        return dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {name: val[idx] for name, val in self.data.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Function for Visualization of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x1, x2, y):\n",
    "    X = StandardScaler().fit_transform(np.concatenate([x1, x2], axis=-1))\n",
    "\n",
    "    plt.title(r'Samples from $p(x_1,x_2)$')\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.scatter(X[:,0], X[:,1], alpha=0.5, color=['red' if y_ == 1 else 'green' for y_ in y])\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.set_ylim(-3,3)\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.distplot(X[:,0], hist=False, kde=True,\n",
    "                 bins=None,\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2})\n",
    "\n",
    "    plt.title(r'$p(x_1)$')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.distplot(X[:,1], hist=False, kde=True,\n",
    "                 bins=None,\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2})\n",
    "    plt.title(r'$p(x_2)$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Function for Visualization of the Predicted (x1,x2) pairs and the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(model, dataset, n=1000):\n",
    "    if isinstance(model, tuple):\n",
    "        x1, x2, y = model\n",
    "    else:\n",
    "        x1, x2, y, _, _ = sample_trained(model.plate_model, n)\n",
    "    X1, X2, Y, = dataset.data['x1'], dataset.data['x2'], dataset.data['label']\n",
    "\n",
    "    #plot(x1, x2, y)\n",
    "    plt.title(r'Joint Distribution')\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.scatter(X1, X2, label='data', alpha=0.5, color=['red' if y_ == 1 else 'red' for y_ in Y])\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.set_ylim(-3,3)\n",
    "    plt.scatter(x1, x2, label='flow', alpha=0.5, color=['blue' if y_ == 1 else 'blue' for y_ in y])\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(-3,3)\n",
    "    ax.set_ylim(-3,3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.distplot(X1, hist=False, kde=True, \n",
    "                 bins=None,color='red',\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2},\n",
    "                 label='data')\n",
    "    sns.distplot(x1, hist=False, kde=True, \n",
    "                 bins=None, color='blue',\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2},\n",
    "                 label='flow')\n",
    "    plt.title(r'$p(x_1)$')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.distplot(X2, hist=False, kde=True, \n",
    "                 bins=None,color='red',\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2},\n",
    "                 label='data')\n",
    "    sns.distplot(x2, hist=False, kde=True, \n",
    "                 bins=None, color='blue',\n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 2},\n",
    "                 label='flow')\n",
    "    plt.title(r'$p(x_2)$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow-Based PyroModule Framework Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "def sumall(tens):\n",
    "    reified = list(tens)  # NOTE: Need the lookahead for initializer, this is an iterator\n",
    "    initializer = torch.zeros_like(reified[0])\n",
    "    reducer = lambda l, memo: memo + l\n",
    "    return reduce(reducer, reified, initializer)\n",
    "\n",
    "def get_logprobs(tr, k):\n",
    "    site = tr.nodes[k]\n",
    "    assert site[\"type\"] == \"sample\" and site[\"is_observed\"], f'{k} is type {site[\"type\"]} and is_observed: {site[\"is_observed\"]}'\n",
    "    return site[\"log_prob\"]\n",
    "\n",
    "def visualize(dataset, model):\n",
    "    with pyro.plate('samples', 1000):\n",
    "        outs = model.model()\n",
    "        x1_flow = outs[0]\n",
    "        x2_flow = outs[1]\n",
    "        y_flow = torch.ones_like(x1_flow)\n",
    "    compare((x1_flow.detach(), x2_flow.detach(), y_flow.detach()), dataset)\n",
    "    \n",
    "def smoke_test(model):\n",
    "    print(model.model())\n",
    "    with pyro.plate('test', 13):\n",
    "        out = model.model()\n",
    "        print(out[0].shape)\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for Conditional Affine Transforms made by [N. Pawlowski+, D. C. Castro+, B. Glocker.](https://github.com/biomedia-mira/deepscm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions.conditional import ConditionalTransformModule, ConditionalTransformedDistribution\n",
    "\n",
    "# from deepscm.distributions.transforms.affine.py\n",
    "class ConditionalAffineTransform(ConditionalTransformModule):\n",
    "    def __init__(self, context_nn, event_dim=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.event_dim = event_dim\n",
    "        self.context_nn = context_nn\n",
    "\n",
    "    def condition(self, context):\n",
    "        loc, log_scale = self.context_nn(context)\n",
    "        scale = torch.exp(log_scale)\n",
    "\n",
    "        ac = T.AffineTransform(loc, scale, event_dim=self.event_dim)\n",
    "        return ac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
