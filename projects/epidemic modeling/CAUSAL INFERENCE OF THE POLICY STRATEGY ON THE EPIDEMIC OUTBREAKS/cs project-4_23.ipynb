{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import EoN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to analyze a list\n",
    "\n",
    "def mean_var_std(list_aim):\n",
    "    return(round(np.mean(list_aim),3),\n",
    "           round(np.var(list_aim),3),\n",
    "           round(np.std(list_aim),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for serach for the agents on each group\n",
    "def I_group(G):\n",
    "    I = []\n",
    "    for i in range(N):\n",
    "        if nx.get_node_attributes(G,'statue')[i]=='I':\n",
    "            I.append(i)\n",
    "    return I\n",
    "\n",
    "def S_group(G): \n",
    "    S = []\n",
    "    for i in range(N):\n",
    "        if nx.get_node_attributes(G,'statue')[i]=='S':\n",
    "            S.append(i)\n",
    "    return S\n",
    "                \n",
    "def R_group(G):\n",
    "    R = []\n",
    "    for i in range(N):\n",
    "        if nx.get_node_attributes(G,'statue')[i]=='R':\n",
    "            R.append(i)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for update the inforamation of each node\n",
    "def update_time(reulst, G, N):\n",
    "    for i in range(N):\n",
    "        if G._node[i]['statue'] == \"S\":\n",
    "            for j in range(len(reulst.node_history(i)[1])):\n",
    "                G._node[i].update({reulst.node_history(i)[1][j]: \n",
    "                               reulst.node_history(i)[0][j]})\n",
    "                G._node[i].update({'S': 0})\n",
    "        elif G._node[i]['statue'] == \"I\":\n",
    "            if len(reulst.node_history(i)[1]) == 2:\n",
    "                G._node[i].update({\"R\": reulst.node_history(i)[0][1]})\n",
    "\n",
    "                \n",
    "def update_status(G, N):\n",
    "    for i in range(N):\n",
    "        if G._node[i]['R']> -0.1:\n",
    "            G._node[i].update({'statue': \"R\"})\n",
    "        elif G._node[i]['I']> - 0.1:\n",
    "            G._node[i].update({'statue': \"I\"})\n",
    "        \n",
    "\n",
    "def update_from(result, G):\n",
    "    for i in range(len(result.transmissions())):\n",
    "        j = result.transmissions()[i][2]\n",
    "        if G._node[j]['From'] == -1:\n",
    "            G._node[j].update({'From': result.transmissions()[i][1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fcuntion to get a sample\n",
    "def simulation_sample(def_p_newman, def_p_whole_on_stage_2_list, def_prob_edges_remove,repeat_time_input,\n",
    "                     rho_set_input, tau_input, gamma_input, N_input, neighbor_input):\n",
    "    \n",
    "    return_result = []\n",
    "    \n",
    "    ## preset paramters\n",
    "    rho_set =  rho_set_input#initial fraction infected\n",
    "    tau =  tau_input\n",
    "    #transmission rate\n",
    "    gamma = gamma_input\n",
    "    #recovery rate\n",
    "\n",
    "    # network basic structure\n",
    "    N = N_input\n",
    "    neigbor = neighbor_input\n",
    "    \n",
    "    # number of run\n",
    "    repeat_time = repeat_time_input\n",
    "    \n",
    "    # build a network\n",
    "    G_stable = nx.generators.random_graphs.newman_watts_strogatz_graph(N, neigbor, def_p_newman)\n",
    "    \n",
    "    # faimly connection\n",
    "    G_stable_basic_edges_list = []\n",
    "    for i in range(0,N-1,3):\n",
    "        G_stable_basic_edges_list.append((i,i+1))\n",
    "        G_stable_basic_edges_list.append((i+1,i+2))\n",
    "        G_stable_basic_edges_list.append((i,i+2))\n",
    "    G_stable_edges_list = [e for e in G_stable.edges]\n",
    "    long_dis_edges_list = [i for i in G_stable_edges_list if i not in G_stable_basic_edges_list]\n",
    "    \n",
    "    # degree of the network\n",
    "    N_degree_list = []\n",
    "    for i in range(N):\n",
    "        N_degree_list = N_degree_list +[G_stable.degree(i)] \n",
    "    network_av_deg = mean_var_std(N_degree_list)[0]\n",
    "    \n",
    "    # diameter of the network\n",
    "    G_diameter = nx.diameter(G_stable)\n",
    "    \n",
    "    #average culster conefficient of the network\n",
    "    G_average_clustering = nx.average_clustering(G_stable)\n",
    "    \n",
    "    # random pick remove list from non-neighbor edages   \n",
    "    G_stable_remove_list = random.sample(long_dis_edges_list, \n",
    "                                         round(len(long_dis_edges_list)*def_prob_edges_remove))\n",
    "    \n",
    "    # inital informaion of each node\n",
    "    for i in range(N):\n",
    "        G_stable._node[i].update({'name':i})\n",
    "        G_stable._node[i].update({'statue':'S'})\n",
    "        G_stable._node[i].update({'From': -1})\n",
    "        G_stable._node[i].update({'S': 0})\n",
    "        G_stable._node[i].update({'I': -1})\n",
    "        G_stable._node[i].update({'R': -1})    \n",
    "    \n",
    "    # random pick the inital infected list \n",
    "    initial_infected_list = random.sample(range(N), round(N*rho_set))\n",
    "    initial_recovered_list = []\n",
    "    for i in initial_infected_list:\n",
    "        G_stable._node[i]['I'] = 0\n",
    "        G_stable._node[i]['statue'] = 'I'\n",
    "        G_stable._node[i]['From'] = None\n",
    "    \n",
    "    # run the simulation on each threshold\n",
    "    for stage_one_threshold in def_p_whole_on_stage_2_list:\n",
    "        start_simu_time = time.time()\n",
    "        # recored each iteration\n",
    "        w_final_sus_num = []\n",
    "        w_final_sus_time = []\n",
    "        w_infected_peak = [] \n",
    "        w_infected_peak_time = []\n",
    "        w_at_time = []\n",
    "\n",
    "        for i in range(repeat_time):\n",
    "            G = G_stable.copy()\n",
    "            result_data = simulation_model_unit_time(G,initial_infected_list, initial_recovered_list, \n",
    "                                                     tau,gamma, 0.5, stage_one_threshold, G_stable_remove_list)\n",
    "            # record all data\n",
    "            result_t = result_data[0]\n",
    "            result_S = result_data[1]\n",
    "            result_I = result_data[2]\n",
    "            result_R = result_data[3]\n",
    "\n",
    "            final_sus_num = result_S[-1]\n",
    "            final_sus_time =  result_t[result_S.index(final_sus_num)]\n",
    "            infected_peak = max(result_I)\n",
    "            infected_peak_time = result_t[result_I.index(infected_peak)]\n",
    "            \n",
    "            w_final_sus_num.append(final_sus_num)\n",
    "            w_final_sus_time.append(final_sus_time)\n",
    "            w_infected_peak.append(infected_peak)\n",
    "            w_infected_peak_time.append(infected_peak_time)\n",
    "            w_at_time.append(result_data[4])\n",
    "\n",
    "        \n",
    "        return_result.append([N+1,def_p_newman, network_av_deg, G_diameter, \n",
    "                              G_average_clustering, def_prob_edges_remove, stage_one_threshold,\n",
    "                              mean_var_std(w_at_time)[0],mean_var_std(w_at_time)[2],\n",
    "                              mean_var_std(w_infected_peak)[0], mean_var_std(w_infected_peak)[2], \n",
    "                              mean_var_std(w_infected_peak_time)[0],mean_var_std(w_infected_peak_time)[2], \n",
    "                              mean_var_std(w_final_sus_num)[0], mean_var_std(w_final_sus_num)[2], \n",
    "                              mean_var_std(w_final_sus_time)[0],mean_var_std(w_final_sus_time)[2]])\n",
    "    return (return_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dataset = pd.DataFrame(columns = ['N','newman_p','av_deg','dia','ave_clu','policy_power','threshold',\n",
    "                                           'a_t_m','a_t_std','I_P_N_m','I_P_N_std','I_P_T_m','I_P_T_std',\n",
    "                                           'S_F_N_m','S_F_N_std','S_F_T_m','S_F_T_std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preset paramters\n",
    "\n",
    "#initial fraction infected\n",
    "rho_set = 0.002\n",
    "#transmission rate\n",
    "tau = 0.14\n",
    "#recovery rate\n",
    "gamma = 0.06\n",
    "\n",
    "# phyiscal network structure based on watts_strogatz_grap \n",
    "N = 1499\n",
    "neighbor = 4\n",
    "\n",
    "# the run of time\n",
    "repeat_time = 10\n",
    "\n",
    "# three dimensions paramters \n",
    "# the probaility to build new link to other agents \n",
    "p_newman_list = [0.3,0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]\n",
    "# the momennt when the policy is applied\n",
    "p_whole_on_stage_2 = [0.01, 0.04, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "# the probability of a social link being removed\n",
    "prob_edges_remove_list =[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,0.9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## record all result of the data\n",
    "analysis_time  = 0\n",
    "## simulation the SIR model with different settings\n",
    "for p_newman in p_newman_list:\n",
    "    for prob_edges_remove in prob_edges_remove_list:\n",
    "        result_simulation  = simulation_sample(p_newman, p_whole_on_stage_2,\n",
    "                                               prob_edges_remove,repeat_time,\n",
    "                                               rho_set, tau, gamma, N, neighbor)\n",
    "        for k in range(len(result_simulation)):\n",
    "            analysis_dataset.loc[analysis_time] = result_simulation[k]\n",
    "            analysis_time +=1\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>newman_p</th>\n",
       "      <th>av_deg</th>\n",
       "      <th>dia</th>\n",
       "      <th>ave_clu</th>\n",
       "      <th>policy_power</th>\n",
       "      <th>threshold</th>\n",
       "      <th>a_t_m</th>\n",
       "      <th>a_t_std</th>\n",
       "      <th>I_P_N_m</th>\n",
       "      <th>I_P_N_std</th>\n",
       "      <th>I_P_T_m</th>\n",
       "      <th>I_P_T_std</th>\n",
       "      <th>S_F_N_m</th>\n",
       "      <th>S_F_N_std</th>\n",
       "      <th>S_F_T_m</th>\n",
       "      <th>S_F_T_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6.965</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N  newman_p  av_deg  dia   ave_clu  policy_power  threshold  a_t_m  \\\n",
       "0  1500.0      0.75   6.965  7.0  0.169058           0.9       0.01  1.198   \n",
       "\n",
       "   a_t_std  I_P_N_m  I_P_N_std  I_P_T_m  I_P_T_std  S_F_N_m  S_F_N_std  \\\n",
       "0      0.0     38.0        0.0   15.123        0.0   1361.0        0.0   \n",
       "\n",
       "   S_F_T_m  S_F_T_std  \n",
       "0   83.655        0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
